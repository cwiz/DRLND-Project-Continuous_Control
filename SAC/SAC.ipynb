{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import progressbar as pb\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from baselines.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "env_name = 'LunarLanderContinuous-v2'\n",
    "\n",
    "env = gym.make(env_name)\n",
    "action_size = env.action_space.shape[0]\n",
    "state_size = env.observation_space.shape[0]\n",
    "\n",
    "num_agents = 20\n",
    "\n",
    "def make_env(env_id, seed):\n",
    "    def _f():\n",
    "        env = gym.make(env_id)\n",
    "        env.seed(seed)\n",
    "        return env\n",
    "    return _f\n",
    "\n",
    "envs = [make_env(env_name, seed) for seed in range(num_agents)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "def interact(action):\n",
    "    if np.isnan(action).any():\n",
    "        print(\"ACHTUNG\")\n",
    "    action = action.reshape(num_agents, action_size) \n",
    "    next_state, reward, done, _ = envs.step(action)\n",
    "    return next_state.reshape(num_agents, -1), np.array(reward).reshape(num_agents, -1), np.array(done).reshape(num_agents, -1)\n",
    "\n",
    "def get_random_action():\n",
    "    actions = []\n",
    "    for _ in range(num_agents):\n",
    "        action = envs.action_space.sample()\n",
    "        actions.append(action)\n",
    "    return np.array(actions).reshape(num_agents, -1)\n",
    "    \n",
    "def reset():\n",
    "    state = envs.reset()\n",
    "    return state.reshape(num_agents, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NET_SIZE = 256\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size=1, n_agents=1, fc1_size=NET_SIZE, fc2_size=NET_SIZE):\n",
    "        super(Policy, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(state_size, fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
    "        self.fc3_mu = nn.Linear(fc2_size, action_size)\n",
    "        self.fc3_std = nn.Linear(fc2_size, action_size)\n",
    "#         self.std = torch.autograd.Variable(torch.ones(action_size)*1e-2, requires_grad=True).to(device)\n",
    "\n",
    "    def forward(self, state, log_std_min=-20, log_std_max=2):\n",
    "        x = torch.relu(self.fc1(state)) \n",
    "        x = torch.relu(self.fc2(x))\n",
    "\n",
    "        mean = self.fc3_mu(x)\n",
    "        std = self.fc3_std(x)\n",
    "        std = torch.clamp(std, log_std_min, log_std_max).exp()\n",
    "\n",
    "        return mean, std\n",
    "    \n",
    "class Value(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size=1, n_agents=1, fc1_size=NET_SIZE, fc2_size=NET_SIZE):\n",
    "        \n",
    "        super(Value, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(state_size, fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
    "        self.fc3 = nn.Linear(fc2_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "class Q(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size, n_agents=1, fc1_size=NET_SIZE, fc2_size=NET_SIZE):\n",
    "        \n",
    "        super(Q, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(state_size + action_size, fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
    "        self.fc3 = nn.Linear(fc2_size, 1)\n",
    "        \n",
    "    def forward(self, s, a):\n",
    "        x = torch.cat([s, a], 1)\n",
    "        x = torch.relu(self.fc1(x)) \n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\gym\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\envs\\gym\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\envs\\gym\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\envs\\gym\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\envs\\gym\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\envs\\gym\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    state_size=state_size, \n",
    "    action_size=action_size,\n",
    "    policy_network=Policy,\n",
    "    value_network=Value,\n",
    "    q_network=Q,\n",
    "    n_agents=num_agents, \n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.policy_network.load_state_dict(torch.load(\"POLICY.pth\"))\n",
    "# agent.value_network_local.load_state_dict(torch.load(\"VALUE_LOCAL.pth\"))\n",
    "# agent.value_network_target.load_state_dict(torch.load(\"VALUE_LOCAL.pth\"))\n",
    "# agent.q_network_1.load_state_dict(torch.load(\"Q_1.pth\"))\n",
    "# agent.q_network_2.load_state_dict(torch.load(\"Q_2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(n_episodes, t_max, print_every):\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=print_every)  # last 100 scores\n",
    "    widget = ['training loop: ', pb.Percentage(), ' ', pb.Bar(), ' ', pb.ETA()]\n",
    "    timer = pb.ProgressBar(widgets=widget, maxval=n_episodes).start()\n",
    "    \n",
    "    frame_counter = 0\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        states = reset()\n",
    "        score = 0\n",
    "        for t in range(t_max):\n",
    "            frame_counter += 1\n",
    "            actions = agent.act(states)\n",
    "            next_states, rewards, dones = interact(actions)\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            states = next_states\n",
    "            score += rewards.mean()\n",
    "            if np.any(dones):\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        agent.writer.add_scalar('score/mean', score, i_episode)\n",
    "#         print(score)\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tScore Mean: {:.2f}\\tScore STD: {:.2f}'.format(i_episode, np.mean(scores_window), np.std(scores_window)))\n",
    "            \n",
    "        timer.update(i_episode)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   5% |##                                        | ETA:   0:40:06"
     ]
    }
   ],
   "source": [
    "%time scores = run(t_max=int(500), n_episodes=int(500), print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
